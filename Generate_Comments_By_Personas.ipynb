{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjZCLDG8i243"
      },
      "source": [
        "No quotation marks in the prompt. Enter your prompt and the play button for that cell. Press play on the pip install cell before doing prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26M1mo3VBKI9",
        "outputId": "894ecbd8-184d-4996-fd63-8b55a3c543b2"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6MFSMBvCZ-q",
        "outputId": "01c120d8-eff0-4a90-a665-5019c189a18d"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQujvtjuqHBB"
      },
      "source": [
        "Load personas.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7-bNJ5kqfac",
        "outputId": "dc25711c-b48e-4ce9-9be0-8b8f771948e3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "def pretty_print(df):\n",
        "    return display( HTML( df.to_html().replace(\"\\\\n\",\"<br>\") ) )\n",
        "\n",
        "dirpath_personas = \"/content/drive/YOUR_PATH\" #@param {type: \"string\"}\n",
        "personas_path = dirpath_personas + 'personas.csv' #@param {type: \"string\"}\n",
        "ndataf = pd.DataFrame()\n",
        "pdataf = pd.DataFrame()\n",
        "pdataf = df=pd.read_csv(personas_path)\n",
        "max_peeps = pdataf.shape[0]\n",
        "max_peeps\n",
        "pdataf.shape\n",
        "#list(pdataf.columns) #deal with space char prefix column names\n",
        "# pretty_print(pdataf)\n",
        "# print(tabulate([list(row) for row in df.values], headers=list(df.columns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJu8PTDfJiYV",
        "outputId": "e40ca75d-13ee-427b-cb8c-fc57d5c7c5a2"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import difflib\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# @title Setup Parameters\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = 'YOUR_KEY'\n",
        "\n",
        "TEMPERATURE = 0.2\n",
        "FREQUENCY_PENALTY = 0.0\n",
        "\n",
        "# Define the maximum number of retries and initial wait time\n",
        "max_retries = 5\n",
        "wait_time = 1  # in seconds\n",
        "\n",
        "system_text = f\"\"\"\n",
        "BACKGROUND TEXT FOR THE RECENT WORLD EVENTS, YOUR CAMPAIGN DESCRIPTION, ....\n",
        "\"\"\"\n",
        "\n",
        "insert_prompt = \"THE ACTUAL PROMPT\"  #@param {type: \"string\"}\n",
        "\n",
        "number_of_results = 2  #@param {type: \"number\"}\n",
        "pick_model = \"gpt-3.5-turbo-16k\"  #@param ['gpt-3.5-turbo-16k', 'gpt-3.5-turbo', 'gpt-4']\n",
        "\n",
        "this_platform = \"Twitter\" #@param {type: \"string\"}\n",
        "response_max_tokens=200 #@param {type: \"number\"}\n",
        "\n",
        "if number_of_results > max_peeps:\n",
        "   number_of_results = max_peeps\n",
        "\n",
        "ndataf = pdataf.iloc[:number_of_results,:16].copy() # truncate\n",
        "ndataf.shape\n",
        "# pretty_print(ndataf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEVxCao7OxhR"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlJndpb6O8Rx"
      },
      "outputs": [],
      "source": [
        "def build_author(me): #can be modified - is used to build the prompt\n",
        "  about_me =  \" I am from \" + me[' location'] \\\n",
        "  + \". my twitter bio is: \" + me[' twitter bio'] \\\n",
        "  + \". I write with a tone and voice of \" + me[' tone and voice'] \\\n",
        "  + \". My geographical and cultural context is: \" + me[' geographical and cultural context'] + \".\" \\\n",
        "  + \" My usual political perspective is based on\" + me[' beliefs and values'] + \".\" \\\n",
        "  + \" My writing style is:\" + me[' writing style'] +\".\"\n",
        "  return about_me\n",
        "\n",
        "\n",
        "def get_completion(messages, model=pick_model, temperature=TEMPERATURE,frequency_penalty=FREQUENCY_PENALTY):\n",
        "#    try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        frequency_penalty=frequency_penalty,\n",
        "    )\n",
        "#        break  # if the request was successful, break the retry loop -- B's error recovery\n",
        "#    except openai.error.ServiceUnavailableError:\n",
        "#            if i < max_retries - 1:  # no need to wait on the last attempt\n",
        "#                time.sleep(wait_time)\n",
        "#                wait_time *= 2  # double the wait time for the next attempt\n",
        "#            else:\n",
        "#                raise  # re-raise the last exception if all retries failed\n",
        "    return response.choices[0].message[\"content\"].strip()\n",
        "\n",
        "\n",
        "def build_prompt_get_completion(persona, system_text, insert_prompt):\n",
        "\n",
        "    mystory = build_author(persona)\n",
        "    prompt1 = f\"\"\"\n",
        "    Write a single tweet using the perspective and voice without being overly personal of {mystory} .\n",
        "    This tweet MUST BE no more than {response_max_tokens} tokens in length but can be shorter.\n",
        "    The tweet must be based on the content of the folowing text: {insert_prompt}.\n",
        "    The response must be in English language.\n",
        "    Do not begin the tweet with 'As of'\n",
        "\"\"\"\n",
        "    messages =  [\n",
        "        {'role':'system', 'content':system_text},\n",
        "        {'role':'user', 'content': prompt1 } ]\n",
        "    response = get_completion(messages)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yScHSA8XN9wR"
      },
      "source": [
        "# Time to build all the responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6BCmXDJk2yd"
      },
      "outputs": [],
      "source": [
        "\n",
        "ndataf['response1'] = ndataf.apply(lambda x: build_prompt_get_completion(x, system_text, insert_prompt), axis=1)\n",
        "\n",
        "savedf = pd.DataFrame(ndataf, columns=[' twitter handle', 'response1'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "mi_CpmeitxAo",
        "outputId": "18b8a033-3ecf-40e0-d728-d377fae27f7a"
      },
      "outputs": [],
      "source": [
        "pretty_print(savedf.head(40))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn0P5mLUNk5p"
      },
      "source": [
        "# Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNqhXGMJNut-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Save to a CSV file\n",
        "abrevstr = ''.join([ s[0] for s in insert_prompt.split() ])\n",
        "date_string = datetime.now().strftime(\"%m-%d-%s\")\n",
        "\n",
        "\n",
        "#df.to_csv(f'/content/out.csv', index=False)\n",
        "savedf.to_csv(f'/content/{date_string}_{abrevstr}.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0cNkVpYyY6y",
        "outputId": "b52150b5-bf1e-4951-f88e-2ccc060b1041"
      },
      "outputs": [],
      "source": [
        "!pwd\n",
        "!ls"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
